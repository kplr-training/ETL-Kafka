<img src=https://www.pngitem.com/pimgs/m/497-4979354_computer-guy-meme-hd-png-download.png width="200"></img>


<details><summary>
  WORKSHOP 1 : Basic Producer Consumer</summary>
  
  - activate the following branch in your local project :<br>
[Basic Producer Consumer Stub](https://github.com/mehdi-lamrani/kafka-central/tree/basic-prod-cons-stub) <br>

  - The goal of this workshop is to build a modular program, implementing custom producers & consumers
  - The entry point is the main class `KafkaCentral`
  - it defines the following [REPL](https://en.wikipedia.org/wiki/Read%E2%80%93eval%E2%80%93print_loop), that will be the control center for your program
    <img width="500" alt="run-jar" src="https://user-images.githubusercontent.com/28993140/82837307-f63c0d80-9ec8-11ea-8c4b-340522f5748e.png">

  - `HelloProducer` & `HelloConsumer` are two static classes with a `run` method that cofigures, defines, and triggers respectively instances of `KafkaProducer` and `KafkaProducer`
  
  - Your mission is to implement those classes and fill them accordingly to what we saw in class (refer to course material)<br>
  in order to have a fully functional producer consumer pipeline
  
  - Once your code is complete, build is using maven build and deploy it to the server using the previously set Source Synchronizer plugin
  
  - Execute your deployed code on the server using java -jar
      - Split your terminal, and launch one KafkaCentral on each
      - Launch a producer on the first
      - Launch a consumer on the second
      
  
  - Validate the behavior of the code : Production & Consumption of the sent events. 
  
  - ***WARNING*** : Kafka Topics are stamped with a hard-coded value. You might need to adjust this later in your code, depending on your branch

<!--[Basic Producer Consumer Solution](https://github.com/mehdi-lamrani/kafka-central/tree/basic-prod-cons-final)-->
</details>

<details><summary>
  WORKSHOP 2 : Remote Producer Consumer</summary> 
  
  - activate the following branch in your local project :<br>
[Alpha Producer Consumer Stub](https://github.com/mehdi-lamrani/kafka-central/tree/alpha-prod-cons-stub) <br>
<!--[Alpha Producer Consumer Solution](https://github.com/mehdi-lamrani/kafka-central/tree/alpha-prod-cons-final)-->
 
  - In this part, we will build a live kafka stream with a real life scenario where the EVENT object needs to be built from the ground up 
  - Serilization and Deserialisation will be performed using the AVRO format for convenience.
  
  - Your will notice new classes and packages : 
    - `alpha.client`
        - A Data Transfer Object (DTO) `OhlcDTO`for [OHLC](https://datavizcatalogue.com/methods/OHLC_chart.html) data 
        - A utility class `AlphaConnect` to connect to a Live Financial Source ([Alpha Vantage](https://www.alphavantage.co/documentation/)) that provides a REST API
        - This class parses the CSV flow from the REST API into a List of `OhlcDTO` to be passed to a dedicated producer
    - `kafka.client`
       -  `AlphaProducer` is a dedicated producer for the Alphva Events  
       -  `AlphaConsumer` is a dedicated consumer for the Alphva Events 
       
  - Your mission is to implement those classes and fill them accordingly in order to have a fully functional flow producer consumer pipeline from an external live source
</details>

<details><summary>
  WORKSHOP 3 : Streams Counter</summary> 
  
  - activate the following branch in your local project :<br>
[Streams Stub](https://github.com/mehdi-lamrani/kafka-central/tree/streams-stub) <br>
<!--[Streams Solution](https://github.com/mehdi-lamrani/kafka-central/tree/stream-final)-->
</details>
